{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Week 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Team 3**\n",
    "- Shinto Machado\n",
    "- Adrián García\n",
    "- Gerard Asbert\n",
    "- Kunal Purkayastha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction and Hypothesis**\n",
    "\n",
    "In this notebook we build and analyse a Bag of Visual Words (BoVW) pipeline for image classification.  \n",
    "The main goal is to understand the role of each component of the pipeline and to identify a good overall configuration by changing one parameter at a time.\n",
    "\n",
    "**Hypothesis:** Our hypothesis is..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bovw import BOVW\n",
    "from main import Dataset, train, test\n",
    "\n",
    "from typing import *\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load dataset, prepare cross validation (3-Fold) and basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Dataset(ImageFolder=\"../places_reduced/train\")\n",
    "data_val   = Dataset(ImageFolder=\"../places_reduced/val\")\n",
    "data = data_train + data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase [Training]: Extracting the descriptors:  29%|██▉       | 2093/7266 [00:22<00:55, 92.54it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m test_data  = [data[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m test_idx]\n\u001b[32m     14\u001b[39m bovw = BOVW()\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m bovw, classifier = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbovw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbovw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m acc = test(dataset=test_data, bovw=bovw, classifier=classifier)\n\u001b[32m     18\u001b[39m accuracies.append(acc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Master/C3/project/project-team-3/Week1/main.py:56\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataset, bovw)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m tqdm.tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)), desc=\u001b[33m\"\u001b[39m\u001b[33mPhase [Training]: Extracting the descriptors\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     55\u001b[39m     image, label = dataset[idx]\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     _, descriptors = bovw._extract_features(image=\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m descriptors  \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     59\u001b[39m         all_descriptors.append(descriptors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/master_C3/lib/python3.12/site-packages/PIL/Image.py:724\u001b[39m, in \u001b[36mImage.__array_interface__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    722\u001b[39m     new[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.tobytes(\u001b[33m\"\u001b[39m\u001b[33mraw\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    723\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m     new[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    725\u001b[39m new[\u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m], new[\u001b[33m\"\u001b[39m\u001b[33mtypestr\u001b[39m\u001b[33m\"\u001b[39m] = _conv_type_shape(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    726\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/master_C3/lib/python3.12/site-packages/PIL/Image.py:800\u001b[39m, in \u001b[36mImage.tobytes\u001b[39m\u001b[34m(self, encoder_name, *args)\u001b[39m\n\u001b[32m    798\u001b[39m output = []\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m     bytes_consumed, errcode, data = \u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m     output.append(data)\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(data), start=1):\n",
    "    print(f\"\\n========== Fold {fold} ==========\")\n",
    "    train_data = [data[i] for i in train_idx]\n",
    "    test_data  = [data[i] for i in test_idx]\n",
    "\n",
    "    bovw = BOVW()\n",
    "    bovw, classifier = train(dataset=train_data, bovw=bovw)\n",
    "\n",
    "    acc = test(dataset=test_data, bovw=bovw, classifier=classifier)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "print(\"\\n========== 3-Fold Cross-Validation ==========\")\n",
    "print(\"Accuracies per fold:\", accuracies)\n",
    "print(\"Average accuracy:\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Different Descriptors (Sift, orb, Akaze and Dense SIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_types = ['DENSE_SIFT', 'SIFT', 'ORB', 'AKAZE']\n",
    "\n",
    "results = {}\n",
    "\n",
    "for det in detector_types:\n",
    "    print(f\"\\n\\n###############################\")\n",
    "    print(f\"### Descriptor: {det}\")\n",
    "    print(f\"###############################\")\n",
    "\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(data), start=1):\n",
    "        print(f\"\\n========== Fold {fold} ==========\")\n",
    "        train_data = [data[i] for i in train_idx]\n",
    "        test_data  = [data[i] for i in test_idx]\n",
    "\n",
    "        # Usar el descriptor correspondiente\n",
    "        bovw = BOVW(detector_type=det)\n",
    "        bovw, classifier = train(dataset=train_data, bovw=bovw)\n",
    "\n",
    "        acc = test(dataset=test_data, bovw=bovw, classifier=classifier)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    print(\"\\n========== 3-Fold Cross-Validation ==========\")\n",
    "    print(\"Accuracies per fold:\", accuracies)\n",
    "    print(\"Average accuracy:\", np.mean(accuracies))\n",
    "\n",
    "    results[det] = {\n",
    "        \"fold_accuracies\": accuracies,\n",
    "        \"mean_accuracy\": np.mean(accuracies)\n",
    "    }\n",
    "\n",
    "print(\"\\n\\n===== Summary over descriptors =====\")\n",
    "for det in detector_types:\n",
    "    print(f\"{det}: mean accuracy = {results[det]['mean_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Resumen por método: media y desviación típica\u001b[39;00m\n\u001b[32m     16\u001b[39m summary = (\n\u001b[32m     17\u001b[39m     df.groupby(\u001b[33m'\u001b[39m\u001b[33mMethod\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     18\u001b[39m       .agg([\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     19\u001b[39m       .reset_index()\n\u001b[32m     20\u001b[39m       .sort_values(\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# orden de menor a mayor\u001b[39;00m\n\u001b[32m     21\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m fig, ax = \u001b[43mplt\u001b[49m.subplots(figsize=(\u001b[32m8\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m     25\u001b[39m y_pos = np.arange(\u001b[38;5;28mlen\u001b[39m(summary))\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Barras horizontales con barras de error (std)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Cross-val w/ 3 folds, obtained in previous experiment using default values for each Local descriptor\n",
    "data = {\n",
    "    'Method': ['AKAZE', 'AKAZE', 'AKAZE', \n",
    "               'ORB', 'ORB', 'ORB',\n",
    "               'SIFT', 'SIFT', 'SIFT',\n",
    "               'DENSE_SIFT', 'DENSE_SIFT', 'DENSE_SIFT'],\n",
    "    'Accuracy': [41.2, 45.7, 48.4,\n",
    "                 42.3, 46.9, 48.7,\n",
    "                 60.2, 66.1, 68.4,\n",
    "                 74.3, 76.6, 80.1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Resumen por método: media y desviación típica\n",
    "summary = (\n",
    "    df.groupby('Method')['Accuracy']\n",
    "      .agg(['mean', 'std'])\n",
    "      .reset_index()\n",
    "      .sort_values('mean')  # orden de menor a mayor\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "y_pos = np.arange(len(summary))\n",
    "\n",
    "# Barras horizontales con barras de error (std)\n",
    "ax.barh(\n",
    "    y_pos,\n",
    "    summary['mean'],\n",
    "    xerr=summary['std'],\n",
    "    align='center',\n",
    "    alpha=0.85,\n",
    "    linewidth=1.2,\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "# Puntos individuales de cada fold (para que se vea la dispersión)\n",
    "for i, method in enumerate(summary['Method']):\n",
    "    xs = df[df['Method'] == method]['Accuracy'].values\n",
    "    # pequeño jitter vertical para que no se solapen exactamente\n",
    "    jitter = np.linspace(-0.12, 0.12, len(xs))\n",
    "    ax.scatter(\n",
    "        xs,\n",
    "        np.full_like(xs, y_pos[i], dtype=float) + jitter,\n",
    "        s=45,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.6,\n",
    "        alpha=0.9\n",
    "    )\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(summary['Method'])\n",
    "ax.set_xlabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Cross-validation accuracy by local descriptor', fontsize=14)\n",
    "\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "ax.set_xlim(40, 85)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Dense Sift with tiny steps and different scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Numerical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Plots and visual results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Different amount of local features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Numerical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Plots and visual results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Different Codebook sizes k (10, 100, 1000, ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###############################\n",
      "### Codebook size: 50\n",
      "###############################\n",
      "\n",
      "========== Fold 1 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase [Training]: Extracting the descriptors: 100%|██████████| 7266/7266 [02:29<00:00, 48.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the codebook\n",
      "Computing the bovw histograms\n",
      "Fitting the classifier\n",
      "Accuracy on Phase[Train]: 0.3222742290748899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase [Eval]: Extracting the descriptors:  28%|██▊       | 1034/3634 [00:22<00:57, 45.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m     bovw = BOVW(detector_type=detector_type, codebook_size=k)\n\u001b[32m     25\u001b[39m     bovw, classifier = train(dataset=train_data, bovw=bovw)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     acc = \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbovw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbovw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     accuracies.append(acc)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m========== 3-Fold Cross-Validation ==========\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Master/C3/project/project-team-3/Week1/main.py:29\u001b[39m, in \u001b[36mtest\u001b[39m\u001b[34m(dataset, bovw, classifier)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m tqdm.tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)), desc=\u001b[33m\"\u001b[39m\u001b[33mPhase [Eval]: Extracting the descriptors\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     28\u001b[39m     image, label = dataset[idx]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     _, descriptors = \u001b[43mbovw\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_extract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m descriptors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     32\u001b[39m         test_descriptors.append(descriptors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Master/C3/project/project-team-3/Week1/bovw.py:43\u001b[39m, in \u001b[36mBOVW._extract_features\u001b[39m\u001b[34m(self, image)\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.detector.compute(image, \u001b[38;5;28mself\u001b[39m.kp(image))\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# SIFT\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetectAndCompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#Numerical results\n",
    "\n",
    "codebook_sizes = [50, 100, 200, 400]\n",
    "\n",
    "detector_type = 'SIFT'\n",
    "\n",
    "results = {}\n",
    "\n",
    "for k in codebook_sizes:\n",
    "    print(f\"\\n\\n###############################\")\n",
    "    print(f\"### Codebook size: {k}\")\n",
    "    print(f\"###############################\")\n",
    "\n",
    "    kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(data), start=1):\n",
    "        print(f\"\\n========== Fold {fold} ==========\")\n",
    "        train_data = [data[i] for i in train_idx]\n",
    "        test_data  = [data[i] for i in test_idx]\n",
    "\n",
    "        # Usar el descriptor correspondiente\n",
    "        bovw = BOVW(detector_type=detector_type, codebook_size=k)\n",
    "        bovw, classifier = train(dataset=train_data, bovw=bovw)\n",
    "\n",
    "        acc = test(dataset=test_data, bovw=bovw, classifier=classifier)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    print(\"\\n========== 3-Fold Cross-Validation ==========\")\n",
    "    print(\"Accuracies per fold:\", accuracies)\n",
    "    print(\"Average accuracy:\", np.mean(accuracies))\n",
    "\n",
    "    results[k] = {\n",
    "        \"fold_accuracies\": accuracies,\n",
    "        \"mean_accuracy\": np.mean(accuracies)\n",
    "    }\n",
    "\n",
    "print(\"\\n\\n===== Summary over codebook_sizes =====\")\n",
    "for k in codebook_sizes:\n",
    "    print(f\"{k}: mean accuracy = {results[k]['mean_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Plots and visual results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Different Classifiers (...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Numerical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Plots and visual results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Dimensionality reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Spatial Pyramids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Fisher Vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Conclusion\n",
    "\n",
    "Our hyphothesis...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_C3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
